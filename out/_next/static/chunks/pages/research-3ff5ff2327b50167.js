(self.webpackChunk_N_E=self.webpackChunk_N_E||[]).push([[465],{8830:function(e,n,i){(window.__NEXT_P=window.__NEXT_P||[]).push(["/research",function(){return i(735)}])},4132:function(e,n,i){"use strict";i.d(n,{Z:function(){return components_Layout}});var s=i(5893),t=i(8329),r=i(8029),a=i(6254),o=i(7294),c=i(3658),l=i(1046),h=i(3636),d=i(8491),x=i(2519),g=i(4234),m=i(4614),j=i(7426),u=i(1360),p=i(7391),f=i(10),b=i(8186),v=i(5560),y=i(7451),w=i(6523),A=i(8389),z=i(1664),C=i.n(z),S=i(8772),k=i(1163),W=i(608),R=i(2095),T=i(4302),L=i(3162),O=i(8204),components_LanguageSwitcher=()=>{let e=(0,k.useRouter)(),{pathname:n,asPath:i,query:t,locale:r}=e,changeLanguage=s=>{e.push({pathname:n,query:t},i,{locale:s})};return(0,s.jsxs)(W.v,{children:[(0,s.jsx)(R.j,{as:d.z,rightIcon:(0,s.jsx)(O.v,{}),variant:"ghost",size:"sm",children:"en"===r?"EN":"PT"}),(0,s.jsxs)(T.q,{children:[(0,s.jsx)(L.s,{onClick:()=>changeLanguage("en"),children:"English"}),(0,s.jsx)(L.s,{onClick:()=>changeLanguage("pt"),children:"Portugu\xeas"})]})]})};let P=[{name:"nav.home",path:"/"},{name:"nav.about",path:"/about"},{name:"nav.research",path:"/research"},{name:"nav.projects",path:"/projects"},{name:"nav.portfolio",path:"/portfolio"},{name:"nav.publications",path:"/publications"},{name:"nav.contact",path:"/contact"}];var components_Header=()=>{let{isOpen:e,onOpen:n,onClose:i}=(0,c.q)(),{colorMode:z,toggleColorMode:k}=(0,l.If)(),[W,R]=(0,o.useState)(!1),{t:T}=(0,S.$G)("common");window.addEventListener("scroll",()=>{window.scrollY>10?R(!0):R(!1)});let L=(0,l.ff)(W?"white":"transparent",W?"gray.800":"transparent"),O=W?"sm":"none";return(0,s.jsxs)(r.x,{as:"header",position:"sticky",top:0,zIndex:100,bg:L,boxShadow:O,transition:"all 0.3s ease",children:[(0,s.jsx)(a.W,{maxW:"container.xl",children:(0,s.jsxs)(t.k,{h:16,alignItems:"center",justifyContent:"space-between",children:[(0,s.jsx)(C(),{href:"/",passHref:!0,children:(0,s.jsx)(r.x,{cursor:"pointer",fontWeight:"bold",fontSize:"xl",children:"Daniel Terra Gomes"})}),(0,s.jsx)(h.U,{spacing:8,alignItems:"center",children:(0,s.jsx)(h.U,{as:"nav",spacing:4,display:{base:"none",md:"flex"},children:P.map(e=>(0,s.jsx)(C(),{href:e.path,passHref:!0,children:(0,s.jsx)(d.z,{variant:"ghost",children:T(e.name)})},e.name))})}),(0,s.jsxs)(t.k,{alignItems:"center",gap:2,children:[(0,s.jsx)(components_LanguageSwitcher,{}),(0,s.jsx)(d.z,{onClick:k,size:"md",variant:"ghost",children:"light"===z?(0,s.jsx)(v.k,{}):(0,s.jsx)(y.N,{})}),(0,s.jsx)(x.h,{size:"md",icon:e?(0,s.jsx)(w.T,{}):(0,s.jsx)(A.U,{}),"aria-label":"Open Menu",display:{md:"none"},onClick:e?i:n})]})]})}),(0,s.jsxs)(g.dy,{isOpen:e,placement:"right",onClose:i,children:[(0,s.jsx)(m.Z,{}),(0,s.jsxs)(j.s,{children:[(0,s.jsx)(u.o,{}),(0,s.jsx)(p.x,{children:"Menu"}),(0,s.jsx)(f.f,{children:(0,s.jsxs)(b.g,{spacing:4,align:"start",children:[P.map(e=>(0,s.jsx)(C(),{href:e.path,passHref:!0,children:(0,s.jsx)(d.z,{variant:"ghost",w:"full",justifyContent:"flex-start",onClick:i,children:T(e.name)})},e.name)),(0,s.jsx)(components_LanguageSwitcher,{})]})})]})]})]})},E=i(3712),I=i(92),_=i(7879),D=i(2553),X=i(9583),components_Footer=()=>{let e=new Date().getFullYear();return(0,s.jsx)(r.x,{as:"footer",bg:(0,l.ff)("gray.50","gray.900"),color:(0,l.ff)("gray.700","gray.200"),mt:"auto",py:6,children:(0,s.jsx)(a.W,{maxW:"container.xl",children:(0,s.jsxs)(E.K,{direction:{base:"column",md:"row"},spacing:4,justify:{base:"center",md:"space-between"},align:{base:"center",md:"center"},children:[(0,s.jsxs)(I.x,{children:["\xa9 ",e," Daniel Terra Gomes. All rights reserved."]}),(0,s.jsxs)(t.k,{gap:4,children:[(0,s.jsx)(_.r,{href:"https://github.com/ARRETdaniel",isExternal:!0,children:(0,s.jsx)(D.J,{as:X.hJX,boxSize:5})}),(0,s.jsx)(_.r,{href:"https://www.linkedin.com/in/arretdaniel",isExternal:!0,children:(0,s.jsx)(D.J,{as:X.ltd,boxSize:5})}),(0,s.jsx)(_.r,{href:"https://twitter.com/arretdaniel",isExternal:!0,children:(0,s.jsx)(D.J,{as:X.fWC,boxSize:5})})]})]})})})},components_Layout=e=>{let{children:n}=e;return(0,s.jsxs)(t.k,{direction:"column",minHeight:"100vh",children:[(0,s.jsx)(components_Header,{}),(0,s.jsx)(r.x,{as:"main",flex:"1",children:(0,s.jsx)(a.W,{maxW:"container.xl",py:8,children:n})}),(0,s.jsx)(components_Footer,{})]})}},735:function(e,n,i){"use strict";i.r(n);var s=i(5893),t=i(9008),r=i.n(t),a=i(4132),o=i(1046),c=i(8029),l=i(6254),h=i(8186),d=i(232),x=i(92),g=i(1089),m=i(8329),j=i(2553),u=i(3636),p=i(4032),f=i(8491),b=i(6561),v=i(1502),y=i(5133),w=i(9109),A=i(449),z=i(7879),C=i(9583),S=i(7735);n.default=()=>{let e=(0,o.ff)("gray.50","gray.900"),n=(0,o.ff)("white","gray.800");return(0,s.jsxs)(a.Z,{children:[(0,s.jsxs)(r(),{children:[(0,s.jsx)("title",{children:"Autonomous Vehicles Research | Daniel Terra Gomes"}),(0,s.jsx)("meta",{name:"description",content:"Explore Daniel Terra Gomes' research on autonomous vehicles, computer vision, and machine learning for self-driving technologies."})]}),(0,s.jsx)(c.x,{as:"section",py:12,bg:e,borderRadius:"lg",mb:8,children:(0,s.jsx)(l.W,{maxW:"container.xl",children:(0,s.jsxs)(h.g,{spacing:6,align:"stretch",children:[(0,s.jsx)(d.X,{as:"h1",size:"2xl",textAlign:"center",bgGradient:"linear(to-r, brand.600, blue.500)",bgClip:"text",children:"Autonomous Vehicles Research"}),(0,s.jsx)(x.x,{fontSize:"xl",textAlign:"center",maxW:"container.md",mx:"auto",children:"Exploring the intersection of computer vision, control systems, and machine learning to enable safer and more efficient autonomous driving technologies."})]})})}),(0,s.jsx)(c.x,{as:"section",mb:16,children:(0,s.jsx)(l.W,{maxW:"container.xl",children:(0,s.jsxs)(g.M,{columns:{base:1,md:2},spacing:10,children:[(0,s.jsxs)(c.x,{children:[(0,s.jsx)(d.X,{as:"h2",size:"xl",mb:6,children:"Research Focus"}),(0,s.jsxs)(h.g,{align:"start",spacing:4,children:[(0,s.jsx)(x.x,{children:"My research focuses on the development and validation of autonomous vehicle systems, with particular emphasis on real-time object detection, control algorithms, and driver assistance systems."}),(0,s.jsx)(x.x,{children:"I specialize in implementing and evaluating control algorithms like PID and Pure Pursuit in the CARLA Simulator, as well as integrating computer vision models such as YOLO for real-time object detection to improve driver assistance capabilities."}),(0,s.jsx)(x.x,{children:"The goal of my work is to bridge the gap between theoretical autonomous driving concepts and practical implementations that can enhance road safety and transportation efficiency."})]})]}),(0,s.jsx)(m.k,{justifyContent:"center",alignItems:"center",children:(0,s.jsx)(c.x,{width:"100%",height:"300px",bg:"gray.200",borderRadius:"md",display:"flex",alignItems:"center",justifyContent:"center",children:(0,s.jsx)(x.x,{fontWeight:"bold",children:"Autonomous Vehicle Research Diagram"})})})]})})}),(0,s.jsx)(c.x,{as:"section",py:12,bg:e,borderRadius:"lg",mb:16,children:(0,s.jsx)(l.W,{maxW:"container.xl",children:(0,s.jsxs)(h.g,{spacing:12,children:[(0,s.jsx)(d.X,{as:"h2",size:"xl",textAlign:"center",children:"Key Research Areas"}),(0,s.jsxs)(g.M,{columns:{base:1,md:3},spacing:8,children:[(0,s.jsxs)(h.g,{bg:n,p:6,borderRadius:"lg",boxShadow:"md",spacing:4,align:"flex-start",height:"100%",children:[(0,s.jsx)(m.k,{w:12,h:12,align:"center",justify:"center",color:"white",rounded:"full",bg:"blue.500",mb:2,children:(0,s.jsx)(j.J,{as:C.BYR,w:6,h:6})}),(0,s.jsx)(d.X,{as:"h3",size:"md",children:"Vehicle Control Systems"}),(0,s.jsx)(x.x,{children:"Implementation and evaluation of control algorithms like PID and Pure Pursuit for autonomous navigation in simulated environments. Focus on path planning, trajectory optimization, and vehicle dynamics."})]}),(0,s.jsxs)(h.g,{bg:n,p:6,borderRadius:"lg",boxShadow:"md",spacing:4,align:"flex-start",height:"100%",children:[(0,s.jsx)(m.k,{w:12,h:12,align:"center",justify:"center",color:"white",rounded:"full",bg:"green.500",mb:2,children:(0,s.jsx)(j.J,{as:C.iNY,w:6,h:6})}),(0,s.jsx)(d.X,{as:"h3",size:"md",children:"Computer Vision for Autonomous Driving"}),(0,s.jsx)(x.x,{children:"Integration of YOLO-based object detection systems for real-time perception. Development of techniques for detecting, tracking, and classifying objects in dynamic driving scenarios."})]}),(0,s.jsxs)(h.g,{bg:n,p:6,borderRadius:"lg",boxShadow:"md",spacing:4,align:"flex-start",height:"100%",children:[(0,s.jsx)(m.k,{w:12,h:12,align:"center",justify:"center",color:"white",rounded:"full",bg:"purple.500",mb:2,children:(0,s.jsx)(j.J,{as:S.CCE,w:6,h:6})}),(0,s.jsx)(d.X,{as:"h3",size:"md",children:"Machine Learning for Self-Driving"}),(0,s.jsx)(x.x,{children:"Application of machine learning techniques to improve decision-making capabilities of autonomous systems. Research on reinforcement learning for complex driving scenarios and neural networks for environment understanding."})]})]})]})})}),(0,s.jsx)(c.x,{as:"section",mb:16,children:(0,s.jsx)(l.W,{maxW:"container.xl",children:(0,s.jsxs)(h.g,{spacing:8,align:"stretch",children:[(0,s.jsx)(d.X,{as:"h2",size:"xl",textAlign:"center",mb:4,children:"Featured Research Project"}),(0,s.jsx)(c.x,{bg:n,p:8,borderRadius:"xl",boxShadow:"lg",children:(0,s.jsxs)(g.M,{columns:{base:1,md:2},spacing:8,children:[(0,s.jsxs)(h.g,{align:"flex-start",spacing:4,children:[(0,s.jsx)(d.X,{as:"h3",size:"lg",children:"Driver Assistance System Based on YOLO Object Detection"}),(0,s.jsxs)(u.U,{spacing:2,mb:2,children:[(0,s.jsx)(p.C,{colorScheme:"blue",children:"CARLA Simulator"}),(0,s.jsx)(p.C,{colorScheme:"green",children:"YOLO"}),(0,s.jsx)(p.C,{colorScheme:"purple",children:"Computer Vision"})]}),(0,s.jsx)(x.x,{children:"This research focuses on developing and validating a driver assistance system based on YOLO object detection, implemented and tested in the CARLA simulator. The system provides real-time feedback to drivers by detecting and classifying objects in the driving environment."}),(0,s.jsx)(x.x,{children:"Key components of this research include:"}),(0,s.jsxs)(h.g,{align:"flex-start",pl:4,spacing:2,children:[(0,s.jsx)(x.x,{children:"• Implementation of YOLOv5 for real-time object detection"}),(0,s.jsx)(x.x,{children:"• Integration with CARLA simulator for realistic testing environments"}),(0,s.jsx)(x.x,{children:"• Development of feedback mechanisms for driver alerts"}),(0,s.jsx)(x.x,{children:"• Performance evaluation metrics for system validation"}),(0,s.jsx)(x.x,{children:"• Comparative analysis with other detection methodologies"})]}),(0,s.jsx)(f.z,{colorScheme:"brand",size:"md",mt:2,children:"View Research Paper"})]}),(0,s.jsx)(m.k,{justifyContent:"center",alignItems:"center",children:(0,s.jsx)(c.x,{width:"100%",height:"300px",bg:"gray.200",borderRadius:"md",display:"flex",alignItems:"center",justifyContent:"center",children:(0,s.jsx)(x.x,{fontWeight:"bold",children:"YOLO Detection in CARLA"})})})]})})]})})}),(0,s.jsx)(c.x,{as:"section",py:12,bg:e,borderRadius:"lg",mb:16,children:(0,s.jsx)(l.W,{maxW:"container.xl",children:(0,s.jsxs)(h.g,{spacing:8,align:"stretch",children:[(0,s.jsx)(d.X,{as:"h2",size:"xl",textAlign:"center",children:"Publications & Presentations"}),(0,s.jsxs)(b.U,{allowToggle:!0,children:[(0,s.jsxs)(v.Q,{children:[(0,s.jsx)("h3",{children:(0,s.jsxs)(y.K,{py:4,children:[(0,s.jsx)(c.x,{flex:"1",textAlign:"left",fontWeight:"bold",children:"Autonomous Vehicles in Brazil and their Technologies (2022)"}),(0,s.jsx)(w.X,{})]})}),(0,s.jsx)(A.H,{pb:4,bg:n,children:(0,s.jsxs)(h.g,{align:"flex-start",spacing:3,children:[(0,s.jsxs)(x.x,{children:[(0,s.jsx)("strong",{children:"Event:"})," Congresso Fluminense de Inicia\xe7\xe3o Cient\xedfica e Tecnol\xf3gica (UENF - CNPq)"]}),(0,s.jsxs)(x.x,{children:[(0,s.jsx)("strong",{children:"Type:"})," Scientific Poster Presentation"]}),(0,s.jsxs)(x.x,{children:[(0,s.jsx)("strong",{children:"Abstract:"})," This presentation explored the current state of autonomous vehicle technologies in Brazil, analyzing the technical requirements, regulatory landscape, and potential implementation challenges in the Brazilian context."]}),(0,s.jsx)(f.z,{size:"sm",colorScheme:"brand",variant:"outline",children:"View Poster"})]})})]}),(0,s.jsxs)(v.Q,{children:[(0,s.jsx)("h3",{children:(0,s.jsxs)(y.K,{py:4,children:[(0,s.jsx)(c.x,{flex:"1",textAlign:"left",fontWeight:"bold",children:"Driving into the Future: Advanced Software and Algorithms Powering Autonomous Vehicles (2023)"}),(0,s.jsx)(w.X,{})]})}),(0,s.jsx)(A.H,{pb:4,bg:n,children:(0,s.jsxs)(h.g,{align:"flex-start",spacing:3,children:[(0,s.jsxs)(x.x,{children:[(0,s.jsx)("strong",{children:"Event:"})," Congresso Fluminense de Inicia\xe7\xe3o Cient\xedfica e Tecnol\xf3gica (UENF - CNPq)"]}),(0,s.jsxs)(x.x,{children:[(0,s.jsx)("strong",{children:"Type:"})," Scientific Poster Presentation"]}),(0,s.jsxs)(x.x,{children:[(0,s.jsx)("strong",{children:"Abstract:"})," This research presented an analysis of cutting-edge algorithms and software frameworks that enable autonomous driving capabilities, with a focus on perception systems, decision-making processes, and control mechanisms."]}),(0,s.jsx)(f.z,{size:"sm",colorScheme:"brand",variant:"outline",children:"View Poster"})]})})]}),(0,s.jsxs)(v.Q,{children:[(0,s.jsx)("h3",{children:(0,s.jsxs)(y.K,{py:4,children:[(0,s.jsx)(c.x,{flex:"1",textAlign:"left",fontWeight:"bold",children:"Exploration and Application of Fundamental Concepts of Autonomous Vehicles (2024)"}),(0,s.jsx)(w.X,{})]})}),(0,s.jsx)(A.H,{pb:4,bg:n,children:(0,s.jsxs)(h.g,{align:"flex-start",spacing:3,children:[(0,s.jsxs)(x.x,{children:[(0,s.jsx)("strong",{children:"Event:"})," Congresso Fluminense de Inicia\xe7\xe3o Cient\xedfica e Tecnol\xf3gica (UENF - CNPq)"]}),(0,s.jsxs)(x.x,{children:[(0,s.jsx)("strong",{children:"Type:"})," Scientific Oral Presentation"]}),(0,s.jsxs)(x.x,{children:[(0,s.jsx)("strong",{children:"Abstract:"})," A comprehensive study on vehicle state estimation, visual perception, and motion planning for autonomous vehicles. This work included practical implementations in the CARLA simulator and comparative analysis of different approaches."]}),(0,s.jsx)(f.z,{size:"sm",colorScheme:"brand",variant:"outline",children:"View Presentation"})]})})]}),(0,s.jsxs)(v.Q,{children:[(0,s.jsx)("h3",{children:(0,s.jsxs)(y.K,{py:4,children:[(0,s.jsx)(c.x,{flex:"1",textAlign:"left",fontWeight:"bold",children:"Driver Assistance System Based on YOLO Object Detection (2025)"}),(0,s.jsx)(w.X,{})]})}),(0,s.jsx)(A.H,{pb:4,bg:n,children:(0,s.jsxs)(h.g,{align:"flex-start",spacing:3,children:[(0,s.jsxs)(x.x,{children:[(0,s.jsx)("strong",{children:"Event:"})," Computer Science Undergraduate Thesis"]}),(0,s.jsxs)(x.x,{children:[(0,s.jsx)("strong",{children:"Type:"})," Bachelor's Thesis"]}),(0,s.jsxs)(x.x,{children:[(0,s.jsx)("strong",{children:"Abstract:"})," This thesis presents the development and validation of a driver assistance system that utilizes YOLO object detection algorithms to enhance vehicle safety through real-time perception of the driving environment. The system was implemented and thoroughly tested in the CARLA simulator to evaluate its performance under various driving conditions."]}),(0,s.jsxs)(u.U,{spacing:4,children:[(0,s.jsx)(f.z,{size:"sm",colorScheme:"brand",children:"Read Full Thesis"}),(0,s.jsx)(f.z,{size:"sm",colorScheme:"brand",variant:"outline",children:"View Code Repository"})]})]})})]})]})]})})}),(0,s.jsx)(c.x,{as:"section",mb:16,children:(0,s.jsx)(l.W,{maxW:"container.xl",children:(0,s.jsxs)(h.g,{spacing:8,align:"stretch",children:[(0,s.jsx)(d.X,{as:"h2",size:"xl",textAlign:"center",children:"Research Tools & Technologies"}),(0,s.jsxs)(g.M,{columns:{base:2,md:4},spacing:8,children:[(0,s.jsxs)(h.g,{children:[(0,s.jsx)(m.k,{w:16,h:16,align:"center",justify:"center",color:"white",rounded:"full",bg:"blue.400",children:(0,s.jsx)(x.x,{fontSize:"xl",fontWeight:"bold",children:"CARLA"})}),(0,s.jsx)(x.x,{fontWeight:"medium",textAlign:"center",children:"CARLA Simulator"})]}),(0,s.jsxs)(h.g,{children:[(0,s.jsx)(m.k,{w:16,h:16,align:"center",justify:"center",color:"white",rounded:"full",bg:"green.400",children:(0,s.jsx)(x.x,{fontSize:"xl",fontWeight:"bold",children:"YOLO"})}),(0,s.jsx)(x.x,{fontWeight:"medium",textAlign:"center",children:"YOLO Object Detection"})]}),(0,s.jsxs)(h.g,{children:[(0,s.jsx)(m.k,{w:16,h:16,align:"center",justify:"center",color:"white",rounded:"full",bg:"purple.400",children:(0,s.jsx)(j.J,{as:S.YCd,w:8,h:8})}),(0,s.jsx)(x.x,{fontWeight:"medium",textAlign:"center",children:"PyTorch"})]}),(0,s.jsxs)(h.g,{children:[(0,s.jsx)(m.k,{w:16,h:16,align:"center",justify:"center",color:"white",rounded:"full",bg:"orange.400",children:(0,s.jsx)(j.J,{as:C.tvD,w:8,h:8})}),(0,s.jsx)(x.x,{fontWeight:"medium",textAlign:"center",children:"Python"})]})]})]})})}),(0,s.jsx)(c.x,{as:"section",py:12,bg:e,borderRadius:"lg",children:(0,s.jsx)(l.W,{maxW:"container.xl",children:(0,s.jsxs)(h.g,{spacing:6,align:"center",textAlign:"center",children:[(0,s.jsx)(d.X,{as:"h2",size:"xl",children:"Interested in Collaboration?"}),(0,s.jsx)(x.x,{fontSize:"lg",maxW:"container.md",children:"I'm always open to research collaborations, academic discussions, or industry partnerships in the fields of autonomous vehicles, computer vision, and machine learning."}),(0,s.jsx)(f.z,{as:z.r,href:"/contact",size:"lg",colorScheme:"brand",_hover:{transform:"translateY(-2px)",boxShadow:"lg"},children:"Get in Touch"})]})})})]})}}},function(e){e.O(0,[445,415,796,771,774,888,179],function(){return e(e.s=8830)}),_N_E=e.O()}]);